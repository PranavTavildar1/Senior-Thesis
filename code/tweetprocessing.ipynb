{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###installing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/pranavtavildar/Desktop/Senior-Thesis/data/monthlydata\")  \n",
    "#creating big csv\n",
    "extension = 'csv'\n",
    "all_filenames = sorted([i for i in glob.glob('*.{}'.format(extension))])\n",
    "#combine all files in the list\n",
    "#all_filenames.remove('CVX-Tweets-12-2022-310.csv')\n",
    "\n",
    "\n",
    "combined_csv = pd.DataFrame()\n",
    "i = 0\n",
    "for f in all_filenames:\n",
    "    try:\n",
    "        df = pd.read_csv(f, encoding='utf-8-sig',lineterminator='\\n')\n",
    "        # df.info()\n",
    "        combined_csv = pd.concat([combined_csv, df], ignore_index=True, verify_integrity=True)\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        print(i, \"files were read and combined properly\")\n",
    "        # df.info()\n",
    "        print(df.describe())\n",
    "        print(f\"Error reading file {f}: {str(e)}\")\n",
    "        \n",
    "\n",
    "# #export to csv\n",
    "combined_csv.to_csv( \"../CVXTweets.csv\", index=False, encoding='utf-8-sig',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/pranavtavildar/Desktop/Senior-Thesis/data\")\n",
    "\n",
    "# Retrieve the data from Yahoo Finance\n",
    "start_date = datetime.date(2021, 1, 1)\n",
    "end_date = datetime.date(2022, 12, 31)\n",
    "\n",
    "cvx_data = yf.download('CVX', start=start_date, end=end_date)\n",
    "\n",
    "cvx_data.to_csv('CVX_stock_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading stock data \n",
    "stock_data = pd.read_csv(\"CVX_stock_data.csv\")\n",
    "stock_data[\"Date\"] = pd.to_datetime(stock_data[\"Date\"])\n",
    "stock_data = stock_data.set_index(\"Date\")\n",
    "\n",
    "# Loading tweets\n",
    "tweets = pd.read_csv(\"CVXTweets.csv\",encoding='utf-8-sig',lineterminator='\\n')\n",
    "tweets[\"Date\"] = pd.to_datetime(tweets[\"Date\"])\n",
    "\n",
    "# Filtering tweets\n",
    "filtered_tweets = tweets.loc[tweets[\"Date\"].dt.date.isin(stock_data.index.date)]\n",
    "\n",
    "# Save the filtered tweets to a new CSV file\n",
    "filtered_tweets.to_csv(\"CVXTweets_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/950pxqcd0zn5rw95_9btv5p00000gn/T/ipykernel_670/2702314473.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if type(tweet) == np.float:\n",
      "/var/folders/kz/950pxqcd0zn5rw95_9btv5p00000gn/T/ipykernel_670/2702314473.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_tweets['cleaned_text'] = filtered_tweets['Text'].apply(clean_tweet)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04 23:47:11+00:00</td>\n",
       "      <td>1346241797039656960</td>\n",
       "      <td>Chevron is my way of getting a high dividend y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-04 22:51:14+00:00</td>\n",
       "      <td>1346227718539649024</td>\n",
       "      <td>Chevron $CVX announced today they'd be holding...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-04 22:38:50+00:00</td>\n",
       "      <td>1346224598740819969</td>\n",
       "      <td>$CVX Advisory: Chevron Corporation’s 4Q 2020 E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04 22:32:53+00:00</td>\n",
       "      <td>1346223100879364102</td>\n",
       "      <td>Advisory: Chevron’s 4Q 2020 Earnings Conferenc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-04 21:57:45+00:00</td>\n",
       "      <td>1346214260553248769</td>\n",
       "      <td>Electric vehicle charging network ChargePoint ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date             Tweet ID  \\\n",
       "0  2021-01-04 23:47:11+00:00  1346241797039656960   \n",
       "1  2021-01-04 22:51:14+00:00  1346227718539649024   \n",
       "2  2021-01-04 22:38:50+00:00  1346224598740819969   \n",
       "3  2021-01-04 22:32:53+00:00  1346223100879364102   \n",
       "4  2021-01-04 21:57:45+00:00  1346214260553248769   \n",
       "\n",
       "                                                Text  Likes  \n",
       "0  Chevron is my way of getting a high dividend y...      0  \n",
       "1  Chevron $CVX announced today they'd be holding...      4  \n",
       "2  $CVX Advisory: Chevron Corporation’s 4Q 2020 E...      0  \n",
       "3  Advisory: Chevron’s 4Q 2020 Earnings Conferenc...      0  \n",
       "4  Electric vehicle charging network ChargePoint ...      0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Preprocessing Tweets\n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    r = tweet.lower()\n",
    "    r = re.sub(\"'\", \"\", r) \n",
    "    r = re.sub(\"@[A-Za-z0-9_]+\",\"\", r)\n",
    "    r = re.sub(\"#[A-Za-z0-9_]+\",\"\", r)\n",
    "    r = re.sub(r'http\\S+', '', r)\n",
    "    r = re.sub('[()!?]', ' ', r)\n",
    "    r = re.sub('\\[.*?\\]',' ', r)\n",
    "    r = re.sub(\"[^a-z0-9]\",\" \", r)\n",
    "    r = r.split()\n",
    "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\"]\n",
    "    r = [w for w in r if not w in stopwords]\n",
    "    r = \" \".join(word for word in r)\n",
    "    return r\n",
    "\n",
    "# Apply the clean_tweet function \n",
    "filtered_tweets['cleaned_text'] = filtered_tweets['Text'].apply(clean_tweet)\n",
    "\n",
    "filtered_tweets.to_csv('CVXTweets_cleaned.csv', index=False)\n",
    "\n",
    "unfiltered_tweets = pd.read_csv(\"CVXTweets_filtered.csv\",encoding='utf-8-sig',lineterminator='\\n')\n",
    "\n",
    "print(unfiltered_tweets.equals(filtered_tweets))\n",
    "unfiltered_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/950pxqcd0zn5rw95_9btv5p00000gn/T/ipykernel_670/1803340424.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_tweets['sentiment'] = filtered_tweets['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-01-04 23:47:11+00:00</td>\n",
       "      <td>1346241797039656960</td>\n",
       "      <td>Chevron is my way of getting a high dividend y...</td>\n",
       "      <td>0</td>\n",
       "      <td>chevron is my way getting high dividend yield ...</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-01-04 22:51:14+00:00</td>\n",
       "      <td>1346227718539649024</td>\n",
       "      <td>Chevron $CVX announced today they'd be holding...</td>\n",
       "      <td>4</td>\n",
       "      <td>chevron cvx announced today theyd be holding t...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-01-04 22:38:50+00:00</td>\n",
       "      <td>1346224598740819969</td>\n",
       "      <td>$CVX Advisory: Chevron Corporation’s 4Q 2020 E...</td>\n",
       "      <td>0</td>\n",
       "      <td>cvx advisory chevron corporation s 4q 2020 ear...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-01-04 22:32:53+00:00</td>\n",
       "      <td>1346223100879364102</td>\n",
       "      <td>Advisory: Chevron’s 4Q 2020 Earnings Conferenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>advisory chevron s 4q 2020 earnings conference...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-01-04 21:57:45+00:00</td>\n",
       "      <td>1346214260553248769</td>\n",
       "      <td>Electric vehicle charging network ChargePoint ...</td>\n",
       "      <td>0</td>\n",
       "      <td>electric vehicle charging network chargepoint ...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date             Tweet ID  \\\n",
       "30 2021-01-04 23:47:11+00:00  1346241797039656960   \n",
       "31 2021-01-04 22:51:14+00:00  1346227718539649024   \n",
       "32 2021-01-04 22:38:50+00:00  1346224598740819969   \n",
       "33 2021-01-04 22:32:53+00:00  1346223100879364102   \n",
       "34 2021-01-04 21:57:45+00:00  1346214260553248769   \n",
       "\n",
       "                                                 Text  Likes  \\\n",
       "30  Chevron is my way of getting a high dividend y...      0   \n",
       "31  Chevron $CVX announced today they'd be holding...      4   \n",
       "32  $CVX Advisory: Chevron Corporation’s 4Q 2020 E...      0   \n",
       "33  Advisory: Chevron’s 4Q 2020 Earnings Conferenc...      0   \n",
       "34  Electric vehicle charging network ChargePoint ...      0   \n",
       "\n",
       "                                         cleaned_text  sentiment  \n",
       "30  chevron is my way getting high dividend yield ...      0.015  \n",
       "31  chevron cvx announced today theyd be holding t...      0.000  \n",
       "32  cvx advisory chevron corporation s 4q 2020 ear...      0.000  \n",
       "33  advisory chevron s 4q 2020 earnings conference...      0.000  \n",
       "34  electric vehicle charging network chargepoint ...      0.000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Sentiment Analysis \n",
    "\n",
    "filtered_tweets['sentiment'] = filtered_tweets['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "filtered_tweets.to_csv('CVXTweets_sentiments.csv', index=False)\n",
    "filtered_tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Debug from here\n",
    "# group the data by Date and calculate the mean sentiment\n",
    "os.chdir(\"/Users/pranavtavildar/Desktop/Senior-Thesis/data\")  \n",
    "filtered_tweets = pd.read_csv(\"CVXTweets_sentiments.csv\",encoding='utf-8-sig',lineterminator='\\n')\n",
    "filtered_tweets['Date'] = pd.to_datetime(filtered_tweets['Date']).dt.date\n",
    "avg_sentiment = filtered_tweets.groupby(['Date'])['sentiment'].mean().reset_index()\n",
    "avg_sentiment.to_csv('daily_sentiments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/950pxqcd0zn5rw95_9btv5p00000gn/T/ipykernel_670/812023121.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  weighted_avg_sentiment = filtered_tweets.groupby(['Date'])['weighted_sentiment', 'adjusted_likes'].sum().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.184861\n",
       "1    0.371769\n",
       "2    0.220826\n",
       "3    0.032773\n",
       "4    0.008593\n",
       "Name: weighted_sentiment, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjusting the weighted sentiment score so that the baseline is 1\n",
    "filtered_tweets['adjusted_likes'] = filtered_tweets['Likes']+1\n",
    "print(min(filtered_tweets['adjusted_likes']))\n",
    "\n",
    "# calculate the weighted sentiment by multiplying the sentiment by Likes\n",
    "filtered_tweets['weighted_sentiment'] = filtered_tweets['sentiment'] * filtered_tweets['adjusted_likes']\n",
    "\n",
    "# group the data by Date and calculate the weighted mean sentiment\n",
    "weighted_avg_sentiment = filtered_tweets.groupby(['Date'])['weighted_sentiment', 'adjusted_likes'].sum().reset_index()\n",
    "weighted_avg_sentiment['weighted_sentiment'] /= weighted_avg_sentiment['adjusted_likes']\n",
    "\n",
    "weighted_avg_sentiment.to_csv('weighted_daily_sentiments.csv', index=False)\n",
    "weighted_avg_sentiment['weighted_sentiment'].head()\n",
    "# missing_dates = weighted_avg_sentiment.loc[weighted_avg_sentiment['weighted_sentiment'].isna()].index\n",
    "# print(missing_dates)\n",
    "# missing_tweets = filtered_tweets[filtered_tweets['Date'].isin(missing_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
